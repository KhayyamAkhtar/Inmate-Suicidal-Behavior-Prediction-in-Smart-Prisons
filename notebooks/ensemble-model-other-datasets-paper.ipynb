{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2458176,"sourceType":"datasetVersion","datasetId":1487904},{"sourceId":4585027,"sourceType":"datasetVersion","datasetId":2673705}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing Packages","metadata":{}},{"cell_type":"code","source":"!pip install dataframe-image\n!pip install pandas==1.5.3\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T07:37:43.617088Z","iopub.execute_input":"2024-02-25T07:37:43.617505Z","iopub.status.idle":"2024-02-25T07:38:05.720930Z","shell.execute_reply.started":"2024-02-25T07:37:43.617472Z","shell.execute_reply":"2024-02-25T07:38:05.719682Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: dataframe-image in /opt/conda/lib/python3.10/site-packages (0.2.3)\nRequirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (1.5.3)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (6.4.5)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (3.8.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (2.31.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (9.5.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (21.3)\nRequirement already satisfied: mistune in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (0.8.4)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (4.9.3)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (4.12.2)\nRequirement already satisfied: cssutils in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (2.9.0)\nRequirement already satisfied: html2image in /opt/conda/lib/python3.10/site-packages (from dataframe-image) (2.0.4.3)\nRequirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (3.1.2)\nRequirement already satisfied: pygments>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (2.15.1)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (0.2.2)\nRequirement already satisfied: traitlets>=5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (5.9.0)\nRequirement already satisfied: jupyter-core in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (5.3.1)\nRequirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (5.9.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (0.4)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (6.0.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (0.7.1)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->dataframe-image) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->dataframe-image) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->dataframe-image) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->dataframe-image) (1.23.5)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dataframe-image) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dataframe-image) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dataframe-image) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dataframe-image) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dataframe-image) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dataframe-image) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dataframe-image) (1.3.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->dataframe-image) (2.3.2.post1)\nRequirement already satisfied: websocket-client<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from html2image->dataframe-image) (1.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->dataframe-image) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->dataframe-image) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->dataframe-image) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->dataframe-image) (2023.7.22)\nRequirement already satisfied: jupyter-client>=6.1.5 in /opt/conda/lib/python3.10/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert>=5->dataframe-image) (7.4.9)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert>=5->dataframe-image) (1.5.6)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert>=5->dataframe-image) (2.17.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert>=5->dataframe-image) (4.17.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.24->dataframe-image) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->dataframe-image) (0.5.1)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core->nbconvert>=5->dataframe-image) (3.10.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=5->dataframe-image) (0.19.3)\nRequirement already satisfied: pyzmq>=23.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert>=5->dataframe-image) (25.1.0)\nRequirement already satisfied: tornado>=6.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert>=5->dataframe-image) (6.3.2)\nRequirement already satisfied: pandas==1.5.3 in /opt/conda/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3) (1.23.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-25T07:38:05.723211Z","iopub.execute_input":"2024-02-25T07:38:05.723555Z","iopub.status.idle":"2024-02-25T07:38:05.735100Z","shell.execute_reply.started":"2024-02-25T07:38:05.723526Z","shell.execute_reply":"2024-02-25T07:38:05.734137Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"/kaggle/input/criminal-psychological-data/Criminal Psychological Dataset CSV.csv\n/kaggle/input/national-survey-of-drug-use-and-health-20152019/NSDUH_2015-2019.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import LeaveOneOut\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, log_loss\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\nfrom imblearn.over_sampling import SMOTE\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import interactive\nimport matplotlib.image as mpimg\nfrom matplotlib.pyplot import figure\n\n# For plotting the classification results\nfrom mlxtend.plotting import plot_decision_regions\nimport xgboost as xgb\nfrom IPython.display import Image  \nfrom six import StringIO\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.metrics import make_scorer, f1_score, accuracy_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-02-25T07:38:05.736474Z","iopub.execute_input":"2024-02-25T07:38:05.736812Z","iopub.status.idle":"2024-02-25T07:38:05.748998Z","shell.execute_reply.started":"2024-02-25T07:38:05.736786Z","shell.execute_reply":"2024-02-25T07:38:05.748079Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Processing","metadata":{}},{"cell_type":"code","source":"#Original suicide dataset\n#reading and preparing datasets\norg_ds = pd.read_csv('/kaggle/input/criminal-psychological-data/Criminal Psychological Dataset CSV.csv')\n\n#converting all columns to lowercase to standardize uss\norg_ds.columns = org_ds.columns.str.lower()\n\n#dataset without non-numeric unwanted fields like date, time, patient number, zero change values\nnumeric_ds = org_ds.drop(['cid','cjdid','staffid','idate','intstrt','instrta','suindt','stjail','pre30jl','pre180jl','cdob',\n                          'chethn1','crace1','c23cmin','c23cmdt','ag1sdin','sdinj30','intend','intenda','editdate','d2bi2pma',\n                          'd2bi2pmb','d2bi2pmc','c18pdmcl','c18pdmcp','c18pdmca','c18spgmc','anytxpm','datadmit','entpro',\n                          'compl','onset1','neworrec','environ','course','worst','worst2','txhispsy','txdralc','hospspec',\n                          'hospmed','othprob3','whowith','currdx','lifedes1','lifedes2','lifedes3','lifetx3','lifedes4',\n                          'lifetx4','lifedes5','lifetx8','screen6a','s61b','s61bs','c17cmdt'] , axis = 1)\n\nprint(\"After removing unimportant fields \" , len(numeric_ds.columns))\n\n#converting categorical values to integer by One Hot Encoding\nnumeric_ds = pd.get_dummies(numeric_ds, columns = ['clive1','job1','majsup1','othoff','othdrug','qtother1',\n                                                             'othtx1','resptx1','a38spgmc','a40spsu','c20spsu','f29spsu',\n                                                             'diff1','diff2','diff3','onset2','new2','othprob1','othprob2',\n                                                             'medvit','alcdrug','freetime','ruleout','lifetx1','lifeage2',\n                                                             'lifetx2','lifetx5','lifedes6','lifetx6','lifedes7','lifetx7','lifedes8'])\n\nprint(\"After converting categorical fields \" , len(numeric_ds.columns))\n\n# replace field that's entirely space (or empty) with NaN\nnumeric_ds = numeric_ds.replace(r'^\\s*$', np.nan, regex=True)\n    \nfor (columnName, columnData) in numeric_ds.iteritems():\n    numeric_ds[columnName] = pd.to_numeric(numeric_ds[columnName])\n    numeric_ds[columnName].fillna(numeric_ds[columnName].mean())\n    numeric_ds[columnName] = numeric_ds[columnName].replace(np.nan, numeric_ds[columnName].mean())\n    numeric_ds[columnName].astype(str).astype(float)\n    \n#removing special characters from feature names added by One Hot Encoding\nimport re\n# Change columns names ([LightGBM] Do not support special JSON characters in feature name. We were using LightGBM initially instead of CatBoost)\nnew_names = {col: re.sub(r'[^A-Za-z0-9_]+', '', col) for col in numeric_ds.columns}\nnew_n_list = list(new_names.values())\n# [LightGBM] Feature appears more than one time.\nnew_names = {col: f'{new_col}_{i}' if new_col in new_n_list[:i] else new_col for i, (col, new_col) in enumerate(new_names.items())}\nnumeric_ds = numeric_ds.rename(columns=new_names)\n\n#important mix of features from anchor's top 19 and 12 features that also co-exist in the other dataset\nimportantFeatures_org = numeric_ds[['age1coc','mhsf28a','sidelf','gain44','age1tob','gs5a','age1mj','sattlf']]\n\n\nthreshold = 0.5  # Set the threshold value\n\n# Convert float values to 0 or 1 based on the threshold\nimportantFeatures_org['age1coc'] = (importantFeatures_org['age1coc'] > threshold).astype(int)\n\nimportantFeatures_org.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-25T07:38:05.751377Z","iopub.execute_input":"2024-02-25T07:38:05.751693Z","iopub.status.idle":"2024-02-25T07:38:09.305722Z","shell.execute_reply.started":"2024-02-25T07:38:05.751668Z","shell.execute_reply":"2024-02-25T07:38:09.304811Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"After removing unimportant fields  860\nAfter converting categorical fields  2337\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/895485643.py:30: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for (columnName, columnData) in numeric_ds.iteritems():\n","output_type":"stream"},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 353 entries, 0 to 352\nData columns (total 8 columns):\n #   Column   Non-Null Count  Dtype\n---  ------   --------------  -----\n 0   age1coc  353 non-null    int64\n 1   mhsf28a  353 non-null    int64\n 2   sidelf   353 non-null    int64\n 3   gain44   353 non-null    int64\n 4   age1tob  353 non-null    int64\n 5   gs5a     353 non-null    int64\n 6   age1mj   353 non-null    int64\n 7   sattlf   353 non-null    int64\ndtypes: int64(8)\nmemory usage: 22.2 KB\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/895485643.py:52: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  importantFeatures_org['age1coc'] = (importantFeatures_org['age1coc'] > threshold).astype(int)\n","output_type":"stream"}]},{"cell_type":"code","source":"#PROCESSED DATASET WITHOUT SUICIDE IDEATION\nx = importantFeatures_org.drop(['sattlf'], axis=1) #X training features\ny = importantFeatures_org.sattlf #y output features\nxTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=3) # 80% training and 20% test","metadata":{"execution":{"iopub.status.busy":"2024-02-25T07:38:09.306912Z","iopub.execute_input":"2024-02-25T07:38:09.307308Z","iopub.status.idle":"2024-02-25T07:38:09.315886Z","shell.execute_reply.started":"2024-02-25T07:38:09.307281Z","shell.execute_reply":"2024-02-25T07:38:09.314998Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Functions & Methods","metadata":{}},{"cell_type":"code","source":"#Creating Dataframe table for displaying of performance metrics for ensemble models\n#required for table image creation\nmetrics_name = [\"Accuracy(%):\", \"F1-Score:\", \"Precision:\", \"Sensitivity:\",\n               \"AUC:\",\"PPV:\", \"Logloss:\" , \"True +:\", \"True -:\",\n               \"False +:\", \"False -:\"]\nmetrics_val = [0,1,2,3,4,5,6,7,8,9,10]\n\ntable_df = pd.DataFrame()\ntable_df[\"Metrics\"] = metrics_name\n\ndef gen_performance_metrics(classifier , YT , YP):\n    TN, FP, FN, TP = confusion_matrix(YT, YP).ravel()\n    metrics_val[0] = round(accuracy_score(YT, YP)*100,2)\n    metrics_val[1] = round(f1_score(YT, YP, average='macro'),3)\n    metrics_val[2] = round(precision_score(YT, YP, average='micro'),3)\n    metrics_val[3] = round(recall_score(YT, YP, average='binary'),3)\n    metrics_val[4] = round(metrics.roc_auc_score(YT, YP),3)\n    metrics_val[5] = round(TP/(TP+FP),3)\n    metrics_val[6] = round(log_loss(YT, YP, eps=1e-5, normalize=True, sample_weight=None, labels=None),3)\n    metrics_val[7] = TP\n    metrics_val[8] = TN\n    metrics_val[9] = FP\n    metrics_val[10] = FN\n    table_df[classifier] = metrics_val\n    print(table_df)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T07:38:09.317549Z","iopub.execute_input":"2024-02-25T07:38:09.318001Z","iopub.status.idle":"2024-02-25T07:38:09.330136Z","shell.execute_reply.started":"2024-02-25T07:38:09.317955Z","shell.execute_reply":"2024-02-25T07:38:09.329249Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Define columns to read, values that co-exist with previous dataset\ncolumns_to_read = ['cocage','mhsuitry','suicthnk','mhsutk_u','cigtry','bkrob','mjage','suictry']\n\n# Read the CSV file and select only the specified columns\nimportant_features_new = pd.read_csv('/kaggle/input/national-survey-of-drug-use-and-health-20152019/NSDUH_2015-2019.csv', \n                                     usecols=columns_to_read)\n\n# Map values to be similar to previous dataset. 1 for yes and 0 for no\nimportant_features_new['suicthnk'] = important_features_new['suicthnk'].map({1:1,2: 0})\nimportant_features_new['bkrob'] = important_features_new['bkrob'].map({1:1,2: 0})\nimportant_features_new['bkrob'] = important_features_new['bkrob'].map({1:1,3: 1})\nimportant_features_new['suictry'] = important_features_new['suictry'].map({1:1,2: 0})\n\n#pre-processing\nimportant_features_new['cocage'].replace(991, 0, inplace=True) #never used cocaine\nimportant_features_new['cigtry'].replace(991, 0, inplace=True) #never used tobacco\nimportant_features_new['mjage'].replace(991, 0, inplace=True) #never used marijuana\nimportant_features_new['cocage'].replace(998, np.nan, inplace=True) #for blank labels\nimportant_features_new['suicthnk'].replace(98, np.nan, inplace=True) #for blank labels\nimportant_features_new['suicthnk'].replace(99, np.nan, inplace=True) #for blank labels\nimportant_features_new['cigtry'].replace(994, np.nan, inplace=True) #for blank labels\nimportant_features_new['bkrob'].replace(98, np.nan, inplace=True) #for blank labels\nimportant_features_new['bkrob'].replace(94, np.nan, inplace=True) #for blank labels\nimportant_features_new['suictry'].replace(98, np.nan, inplace=True) #for blank labels\nimportant_features_new['suictry'].replace(99, np.nan, inplace=True) #for blank labels\n\n#removing bad rows\nimportant_features_new = important_features_new[important_features_new['cocage'] != 998]\nimportant_features_new = important_features_new[important_features_new['cocage'] != 994]\nimportant_features_new = important_features_new[important_features_new['cocage'] != 997]\nimportant_features_new = important_features_new[important_features_new['suicthnk'] != 85]\nimportant_features_new = important_features_new[important_features_new['suicthnk'] != 94]\nimportant_features_new = important_features_new[important_features_new['suicthnk'] != 97]\nimportant_features_new = important_features_new[important_features_new['cigtry'] != 985]\nimportant_features_new = important_features_new[important_features_new['cigtry'] != 994]\nimportant_features_new = important_features_new[important_features_new['bkrob'] != 85]\nimportant_features_new = important_features_new[important_features_new['bkrob'] != 89]\nimportant_features_new = important_features_new[important_features_new['bkrob'] != 97]\nimportant_features_new = important_features_new[important_features_new['bkrob'] != 99]\nimportant_features_new = important_features_new[important_features_new['suictry'] != 85]\nimportant_features_new = important_features_new[important_features_new['suictry'] != 97]\n\n# replace field that's entirely space (or empty) with NaN\nimportant_features_new = important_features_new.replace(r'^\\s*$', np.nan, regex=True)\n    \nfor (columnName, columnData) in important_features_new.iteritems():\n    important_features_new[columnName] = pd.to_numeric(important_features_new[columnName])\n    important_features_new[columnName].fillna(important_features_new[columnName].mean())\n    important_features_new[columnName] = important_features_new[columnName].replace(np.nan, important_features_new[columnName].mean())\n    important_features_new[columnName].astype(str).astype(float)\n    \n    \n# Assuming 'float_column' is the name of your float column\nthreshold = 0.5  # Set the threshold value\n\n# Convert float values to 0 or 1 based on the threshold\nimportant_features_new['bkrob'] = (important_features_new['bkrob'] > threshold).astype(int)\nimportant_features_new['suicthnk'] = (important_features_new['suicthnk'] > threshold).astype(int)\nimportant_features_new['mhsutk_u'] = (important_features_new['mhsutk_u'] > threshold).astype(int)\nimportant_features_new['mhsuitry'] = (important_features_new['mhsuitry'] > threshold).astype(int)\nimportant_features_new['suictry'] = (important_features_new['suictry'] > threshold).astype(int)\n\n\nprint(\"After taking relevant columns only\" , len(important_features_new.columns))\n# Display details about the columns in the DataFrame\nimportant_features_new.info()\nprint(important_features_new['suictry'])\n\n# Rename columns in the testing data to match the training data from previous dataset\nimportant_features_new = important_features_new.rename(columns={'cigtry':'age1tob','mjage':'age1mj','cocage': 'age1coc','bkrob':'gs5a','suicthnk':'sidelf','mhsutk_u':'gain44','mhsuitry':'mhsf28a','suictry':'sattlf'})\n\n# Reorder columns in the testing data to match the order expected by the model\nimportant_features_new = important_features_new[['age1tob', 'age1mj', 'age1coc', 'gs5a', 'sidelf', 'gain44', 'mhsf28a', 'sattlf']]\n\n\nxB = important_features_new.drop(['sattlf'], axis=1) #X training features\nyB = important_features_new.sattlf #y output features\nxTrainB, xTestB, yTrainB, yTestB = train_test_split(xB, yB, test_size=0.9, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T07:38:09.331658Z","iopub.execute_input":"2024-02-25T07:38:09.332252Z","iopub.status.idle":"2024-02-25T07:38:31.075636Z","shell.execute_reply.started":"2024-02-25T07:38:09.332222Z","shell.execute_reply":"2024-02-25T07:38:31.074310Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/3166019888.py:46: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for (columnName, columnData) in important_features_new.iteritems():\n","output_type":"stream"},{"name":"stdout","text":"After taking relevant columns only 8\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 281739 entries, 0 to 282767\nData columns (total 8 columns):\n #   Column    Non-Null Count   Dtype  \n---  ------    --------------   -----  \n 0   cigtry    281739 non-null  float64\n 1   mjage     281739 non-null  int64  \n 2   cocage    281739 non-null  float64\n 3   bkrob     281739 non-null  int64  \n 4   suicthnk  281739 non-null  int64  \n 5   suictry   281739 non-null  int64  \n 6   mhsutk_u  281739 non-null  int64  \n 7   mhsuitry  281739 non-null  int64  \ndtypes: float64(2), int64(6)\nmemory usage: 19.3 MB\n0         0\n1         0\n2         0\n3         0\n4         0\n         ..\n282763    0\n282764    0\n282765    0\n282766    0\n282767    0\nName: suictry, Length: 281739, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Ensemble Method","metadata":{}},{"cell_type":"code","source":"#ensemble techniques for classifiers\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.metrics import accuracy_score\n\n# Create classifer objects for XGBoost and Random Forest models\nxgbModel = xgb.XGBClassifier(objective=\"binary:logistic\", learning_rate=0.3, \n                           booster='gbtree', max_depth=5, n_estimators=100, enable_categorical=False)\nrandomForestModel = RandomForestClassifier(n_estimators=500)\n\n#Voting ensemble classifier of XGboost and Random Forest \nclass_model = VotingClassifier(\n    estimators=[('xgb', xgbModel),('ranFor',randomForestModel)], voting='hard')\n\n\n# training all the model on the train dataset\nxTrain = xTrain[['age1tob', 'age1mj', 'age1coc', 'gs5a', 'sidelf', 'gain44', 'mhsf28a']]\nclass_model.fit(xTrain, yTrain)\n# predicting the output on the test dataset\nxTest = xTest[['age1tob', 'age1mj', 'age1coc', 'gs5a', 'sidelf', 'gain44', 'mhsf28a']]\ny_pred = class_model.predict(xTest)\nxTestB = xTestB[['age1tob', 'age1mj', 'age1coc', 'gs5a', 'sidelf', 'gain44', 'mhsf28a']]\ny_predB = class_model.predict(xTestB)\n\n    \ngen_performance_metrics(\"ENS\" , yTest, y_pred)\ngen_performance_metrics(\"ENS-B\" , yTestB, y_predB)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T07:38:31.077392Z","iopub.execute_input":"2024-02-25T07:38:31.078583Z","iopub.status.idle":"2024-02-25T07:38:41.473736Z","shell.execute_reply.started":"2024-02-25T07:38:31.078542Z","shell.execute_reply":"2024-02-25T07:38:41.472601Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"         Metrics     ENS\n0   Accuracy(%):  95.770\n1      F1-Score:   0.900\n2     Precision:   0.958\n3   Sensitivity:   0.778\n4           AUC:   0.881\n5           PPV:   0.875\n6       Logloss:   0.486\n7        True +:   7.000\n8        True -:  61.000\n9       False +:   1.000\n10      False -:   2.000\n         Metrics     ENS       ENS-B\n0   Accuracy(%):  95.770      99.560\n1      F1-Score:   0.900       0.880\n2     Precision:   0.958       0.996\n3   Sensitivity:   0.778       1.000\n4           AUC:   0.881       0.998\n5           PPV:   0.875       0.617\n6       Logloss:   0.486       0.051\n7        True +:   7.000    1813.000\n8        True -:  61.000  250627.000\n9       False +:   1.000    1126.000\n10      False -:   2.000       0.000\n","output_type":"stream"}]}]}